# 0_hello_deeplearning.py
print("=== ç¬¬0æ­¥ï¼šæ·±åº¦å­¦ä¹ 'Hello World' ===")
print("ç›®æ ‡ï¼šç†è§£æœ€åŸºæœ¬çš„ç¥ç»ç½‘ç»œï¼Œå°±åƒ1+1=2ä¸€æ ·ç®€å•")

# 1. å¯¼å…¥å¿…è¦çš„åº“
import torch
import torch.nn as nn
import numpy as np

print("\nğŸ¯ ç›®æ ‡ï¼šç”¨ç¥ç»ç½‘ç»œå­¦ä¹  y = 2x + 1")
print("   è¾“å…¥x: 1, 2, 3, 4")
print("   è¾“å‡ºy: 3, 5, 7, 9 (å› ä¸º y = 2x + 1)")
print("   è®©ç½‘ç»œè‡ªå·±å‘ç°è¿™ä¸ªè§„å¾‹ï¼")

# 2. å‡†å¤‡æœ€ç®€å•çš„æ•°æ®
# åˆ›å»ºè®­ç»ƒæ•°æ®
x_train = torch.tensor([[1.0], [2.0], [3.0], [4.0]], dtype=torch.float32)
y_train = torch.tensor([[3.0], [5.0], [7.0], [9.0]], dtype=torch.float32)

print(f"\nğŸ“Š è®­ç»ƒæ•°æ®:")
for i in range(len(x_train)):
    print(f"  x={x_train[i].item()}, y={y_train[i].item()}")


# 3. å®šä¹‰æœ€ç®€å•çš„ç¥ç»ç½‘ç»œ
# åªæœ‰ä¸€ä¸ªç¥ç»å…ƒï¼æ²¡æœ‰éšè—å±‚ï¼
class SimplestNet(nn.Module):
    def __init__(self):
        super().__init__()
        # ä¸€ä¸ªçº¿æ€§å±‚ï¼šy = wx + b
        # è¾“å…¥1ä¸ªç‰¹å¾ï¼Œè¾“å‡º1ä¸ªå€¼
        self.linear = nn.Linear(1, 1)

    def forward(self, x):
        return self.linear(x)


# 4. åˆ›å»ºæ¨¡å‹
model = SimplestNet()
print("\nğŸ§  æ¨¡å‹ç»“æ„ï¼ˆè¶…çº§ç®€å•ï¼ï¼‰:")
print(model)
print(f"å¯å­¦ä¹ å‚æ•°:")
for name, param in model.named_parameters():
    print(f"  {name}: {param.data}")

# 5. æŸ¥çœ‹åˆå§‹é¢„æµ‹ï¼ˆè¿˜æ²¡è®­ç»ƒï¼Œæ‰€ä»¥æ˜¯éšæœºçš„ï¼‰
print("\nğŸ”® è®­ç»ƒå‰çš„é¢„æµ‹ï¼ˆå¾ˆå¯èƒ½æ˜¯é”™çš„ï¼‰:")
with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦
    for x in x_train:
        prediction = model(x)
        print(f"  è¾“å…¥ {x.item():.1f} â†’ é¢„æµ‹ {prediction.item():.4f}")

# 6. å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = nn.MSELoss()  # å‡æ–¹è¯¯å·®æŸå¤±
optimizer = torch.optim.SGD(model.parameters(), lr=0.001)  # éšæœºæ¢¯åº¦ä¸‹é™

print("\nğŸ¯ æŸå¤±å‡½æ•°: å‡æ–¹è¯¯å·® (MSE)")
print("   è¡¡é‡é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å·®è·ï¼Œè¶Šå°è¶Šå¥½")
print("ğŸ¯ ä¼˜åŒ–å™¨: SGD (éšæœºæ¢¯åº¦ä¸‹é™)")
print("   å­¦ä¹ ç‡: 0.01 (æ¯æ¬¡è°ƒæ•´çš„æ­¥ä¼å¤§å°)")

# 7. å¼€å§‹è®­ç»ƒï¼æœ€ç®€å•çš„è®­ç»ƒå¾ªç¯
print("\nğŸš€ å¼€å§‹è®­ç»ƒï¼")
epochs = 2000
for epoch in range(epochs):  # é‡å¤å­¦ä¹ å¾ˆå¤šæ¬¡
    # 1. ç”¨å½“å‰å‚æ•°åšé¢„æµ‹
    outputs = model(x_train)

    # 2. è®¡ç®—é¢„æµ‹æœ‰å¤šç³Ÿç³•
    loss = criterion(outputs, y_train)

    # 3. åˆ†æé”™è¯¯åŸå› 
    optimizer.zero_grad()  # å¿˜è®°ä¹‹å‰çš„é”™è¯¯
    loss.backward()  # åˆ†æè¿™æ¬¡é”™åœ¨å“ª

    # 4. è°ƒæ•´å‚æ•°
    optimizer.step()  # ä¿®æ­£é”™è¯¯

    # æ¯10ä¸ªepochæ‰“å°ä¸€æ¬¡
    if (epoch + 1) % 10 == 0:
        print(f"  Epoch {epoch + 1:3d}/{epochs}, Loss: {loss.item():.6f}")

# 8. æŸ¥çœ‹è®­ç»ƒåçš„å‚æ•°
print("\nâœ… è®­ç»ƒå®Œæˆï¼")
print(f"\nğŸ“ˆ å­¦åˆ°çš„å‚æ•°:")
for name, param in model.named_parameters():
    print(f"  {name}: {param.data}")
    if 'weight' in name:
        print(f"    ç½‘ç»œå­¦åˆ°çš„ w â‰ˆ {param.data.item():.4f}")
    else:
        print(f"    ç½‘ç»œå­¦åˆ°çš„ b â‰ˆ {param.data.item():.4f}")

print("\nğŸ¯ çœŸå®çš„å‚æ•°åº”è¯¥æ˜¯: w=2, b=1")

# 9. æµ‹è¯•æ¨¡å‹
print("\nğŸ”® è®­ç»ƒåçš„é¢„æµ‹:")
with torch.no_grad():
    for x in x_train:
        prediction = model(x)
        true_y = 2 * x.item() + 1
        error = abs(prediction.item() - true_y)
        print(f"  è¾“å…¥ {x.item():.1f} â†’ é¢„æµ‹ {prediction.item():.4f}, çœŸå® {true_y}, è¯¯å·® {error:.4f}")

# 10. åœ¨æ–°æ•°æ®ä¸Šæµ‹è¯•
print("\nğŸ§ª åœ¨æ–°æ•°æ®ä¸Šæµ‹è¯•ï¼ˆæ³›åŒ–èƒ½åŠ›ï¼‰:")
test_x = torch.tensor([[5.0], [6.0], [100]], dtype=torch.float32)
with torch.no_grad():
    for x in test_x:
        prediction = model(x)
        true_y = 2 * x.item() + 1
        print(f"  è¾“å…¥ {x.item():.1f} â†’ é¢„æµ‹ {prediction.item():.4f}, çœŸå® {true_y}")

print("\n" + "=" * 50)
print("ğŸ‰ æ­å–œï¼ä½ å®Œæˆäº†ç¬¬ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼")
print("=" * 50)

# ä¸åŒå­¦ä¹ ç‡çš„è¡¨ç°ï¼š
# lr=0.1ï¼šå¯èƒ½éœ‡è¡ï¼Œä½†æ”¶æ•›å¿«
# lr=0.01ï¼šæ•ˆæœæœ€å¥½
# lr=0.001ï¼š50ä¸ªepochå­¦ä¸å®Œ
# lr=0.0001ï¼šåŸºæœ¬æ²¡å­¦