# 01_ç†è§£è®­ç»ƒå¾ªç¯.py
print("=== ç†è§£è®­ç»ƒå¾ªç¯çš„4è¡Œä»£ç  ===")
print()

# 1. å…ˆçœ‹æœ€ç®€å•çš„ä¾‹å­
print("ğŸ¯ æœ€ç®€å•çš„æ•°å­¦é¢˜ï¼š")
print("  å°æ˜æƒ³çŒœä¸€ä¸ªæ•°ï¼šy = 2x + 1")
print("  å·²çŸ¥ï¼šx=1æ—¶y=3, x=2æ—¶y=5")
print("  é—®ï¼šå°æ˜è¦æ€ä¹ˆçŒœï¼Ÿ")

# 2. æ¨¡æ‹Ÿå°æ˜çŒœæ•°å­—çš„è¿‡ç¨‹
print("\n" + "=" * 50)
print("å°æ˜çŒœæ•°å­—çš„è¿‡ç¨‹ï¼š")
print("=" * 50)

# å°æ˜çš„åˆå§‹çŒœæµ‹
w_guess = 0.5  # çŒœ y = 0.5x
b_guess = 0.0  # çŒœ y = 0.5x + 0

learning_rate = 0.1  # æ¯æ¬¡è°ƒæ•´çš„å¤§å°
steps = 5  # çŒœ5æ¬¡

for step in range(steps):
    print(f"\nç¬¬{step + 1}æ¬¡çŒœæµ‹ï¼š")

    # 1. ç”¨å½“å‰çŒœæµ‹åšé¢„æµ‹
    y1_guess = w_guess * 1 + b_guess
    y2_guess = w_guess * 2 + b_guess

    print(f"  çŒœçš„è§„å¾‹ï¼šy = {w_guess:.2f}x + {b_guess:.2f}")
    print(f"  é¢„æµ‹ï¼šx=1 â†’ {y1_guess:.2f}, x=2 â†’ {y2_guess:.2f}")

    # 2. è®¡ç®—é”™è¯¯ç¨‹åº¦
    error1 = y1_guess - 3  # çœŸå®æ˜¯3
    error2 = y2_guess - 5  # çœŸå®æ˜¯5
    total_error = (error1 ** 2 + error2 ** 2) / 2

    print(f"  é”™è¯¯ï¼šx=1å·®äº†{error1:.2f}, x=2å·®äº†{error2:.2f}")
    print(f"  æ€»é”™è¯¯ï¼š{total_error:.2f}")

    # 3. åˆ†æé”™è¯¯åŸå› 
    # è®¡ç®—wå’Œbåº”è¯¥æ€ä¹ˆè°ƒæ•´
    w_grad = error1 * 1 + error2 * 2  # æ¢¯åº¦
    b_grad = error1 + error2  # æ¢¯åº¦

    print(f"  åˆ†æï¼šwåº”è¯¥è°ƒæ•´ {-learning_rate * w_grad:.4f}")
    print(f"        båº”è¯¥è°ƒæ•´ {-learning_rate * b_grad:.4f}")

    # 4. è°ƒæ•´çŒœæµ‹
    w_guess = w_guess - learning_rate * w_grad
    b_guess = b_guess - learning_rate * b_grad

print(f"\næœ€ç»ˆçŒœæµ‹ï¼šy = {w_guess:.2f}x + {b_guess:.2f}")
print("æ­£ç¡®ç­”æ¡ˆï¼šy = 2.00x + 1.00")

# 3. ç±»æ¯”è§£é‡Š
print("\n" + "=" * 50)
print("ç”¨è€ƒè¯•å¤ä¹ æ¥ç†è§£ï¼š")
print("=" * 50)

print("""
å‡è®¾ä½ è€ƒè¯•å¾—60åˆ†ï¼Œæƒ³è€ƒ100åˆ†ï¼š

ç¬¬1è½®å¤ä¹ ï¼š
1ï¸âƒ£ åšä¸€å¥—é¢˜ (å‰å‘ä¼ æ’­)
   - ç”¨å½“å‰çŸ¥è¯†ç­”é¢˜

2ï¸âƒ£ æ‰¹æ”¹å¾—åˆ† (è®¡ç®—æŸå¤±)
   - å¾—äº†60åˆ†
   - æŸå¤± = 100-60=40åˆ†

3ï¸âƒ£ åˆ†æé”™é¢˜ (åå‘ä¼ æ’­)
   - å¿˜è®°ä¹‹å‰çš„é”™é¢˜åˆ†æ
   - åˆ†æï¼šé€‰æ‹©é¢˜é”™3é“ï¼Œè®¡ç®—é¢˜é”™2é“

4ï¸âƒ£ é’ˆå¯¹æ€§å­¦ä¹  (å‚æ•°æ›´æ–°)
   - å¤šç»ƒé€‰æ‹©é¢˜
   - å¤šç»ƒè®¡ç®—é¢˜

ç¬¬2è½®å¤ä¹ ï¼š
å†ç”¨æ–°å­¦çš„çŸ¥è¯†åšé¢˜...
å¦‚æ­¤é‡å¤ç›´åˆ°è€ƒ100åˆ†ï¼
""")

# 4. ä»£ç é€è¡Œè§£é‡Š
print("\n" + "=" * 50)
print("ä»£ç é€è¡Œè§£é‡Šï¼š")
print("=" * 50)

print("""
for epoch in range(epochs):  â† é‡å¤å­¦ä¹ å¾ˆå¤šé
    # å°±åƒè€ƒè¯•å¤ä¹ å¾ˆå¤šæ¬¡

    outputs = model(x_train)  â† ç”¨å½“å‰çŸ¥è¯†åšé¢˜
    # ç”¨å½“å‰çš„w,bå‚æ•°è®¡ç®—é¢„æµ‹å€¼

    loss = criterion(outputs, y_train)  â† æ‰¹æ”¹å¾—åˆ†
    # è®¡ç®—é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å·®è·

    optimizer.zero_grad()  â† æ¸…ç©ºä¹‹å‰çš„é”™é¢˜æœ¬
    # ä¸è®°ä½ä¹‹å‰çš„é”™è¯¯åˆ†æï¼Œåªåˆ†æè¿™æ¬¡çš„

    loss.backward()  â† åˆ†æè¿™æ¬¡é”™åœ¨å“ªé‡Œ
    # è®¡ç®—ï¼šwé”™äº†å¤šå°‘ï¼Ÿbé”™äº†å¤šå°‘ï¼Ÿ

    optimizer.step()  â† æ ¹æ®åˆ†æç»“æœè°ƒæ•´
    # è°ƒæ•´wå’Œbï¼Œè®©ä¸‹æ¬¡é¢„æµ‹æ›´å‡†
""")