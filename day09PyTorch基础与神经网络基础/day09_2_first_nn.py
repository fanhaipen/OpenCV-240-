# day09_first_nn.py
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from sklearn.datasets import make_moons
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

print("ğŸ¯ ç¬¬9å¤©ï¼šåˆ›å»ºç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œ")
print("=" * 50)

# 1. ç”Ÿæˆæ•°æ®
print("1. ç”Ÿæˆæ•°æ®é›†...")
X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)
print(f"æ•°æ®é›†å½¢çŠ¶: X={X.shape}, y={y.shape}")

# å¯è§†åŒ–æ•°æ®
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolors='k')
plt.title("åŸå§‹æ•°æ®åˆ†å¸ƒ")
plt.xlabel("ç‰¹å¾1")
plt.ylabel("ç‰¹å¾2")

# 2. æ•°æ®é¢„å¤„ç†
print("2. æ•°æ®é¢„å¤„ç†...")
# æ ‡å‡†åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# åˆ†å‰²æ•°æ®é›†
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# è½¬æ¢ä¸ºPyTorchå¼ é‡
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)

print(f"è®­ç»ƒé›†: {X_train_tensor.shape}, æµ‹è¯•é›†: {X_test_tensor.shape}")

# 3. å®šä¹‰ç¥ç»ç½‘ç»œ
print("3. å®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹...")


class SimpleNN(nn.Module):
    """ç®€å•çš„ä¸‰å±‚ç¥ç»ç½‘ç»œ"""

    def __init__(self, input_size=2, hidden_size=10, output_size=1):
        super(SimpleNN, self).__init__()
        self.layer1 = nn.Linear(input_size, hidden_size)
        self.layer2 = nn.Linear(hidden_size, hidden_size)
        self.layer3 = nn.Linear(hidden_size, output_size)
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.layer2(x)
        x = self.relu(x)
        x = self.layer3(x)
        x = self.sigmoid(x)
        return x


# åˆ›å»ºæ¨¡å‹å®ä¾‹
model = SimpleNN()
print(f"æ¨¡å‹ç»“æ„:\n{model}")

# 4. å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = nn.BCELoss()  # äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±
optimizer = optim.Adam(model.parameters(), lr=0.01)

# 5. è®­ç»ƒæ¨¡å‹
print("4. å¼€å§‹è®­ç»ƒæ¨¡å‹...")
num_epochs = 1000
train_losses = []
test_losses = []
train_accuracies = []
test_accuracies = []

for epoch in range(num_epochs):
    # è®­ç»ƒæ¨¡å¼
    model.train()

    # å‰å‘ä¼ æ’­
    y_pred = model(X_train_tensor)
    loss = criterion(y_pred, y_train_tensor)

    # åå‘ä¼ æ’­
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # è®¡ç®—å‡†ç¡®ç‡
    with torch.no_grad():
        # è®­ç»ƒé›†å‡†ç¡®ç‡
        train_predictions = (y_pred > 0.5).float()
        train_accuracy = (train_predictions == y_train_tensor).float().mean()

        # æµ‹è¯•é›†å‡†ç¡®ç‡
        model.eval()
        y_test_pred = model(X_test_tensor)
        test_loss = criterion(y_test_pred, y_test_tensor)
        test_predictions = (y_test_pred > 0.5).float()
        test_accuracy = (test_predictions == y_test_tensor).float().mean()

    # è®°å½•æŸå¤±å’Œå‡†ç¡®ç‡
    train_losses.append(loss.item())
    test_losses.append(test_loss.item())
    train_accuracies.append(train_accuracy.item())
    test_accuracies.append(test_accuracy.item())

    # æ¯100ä¸ªepochæ‰“å°ä¸€æ¬¡
    if (epoch + 1) % 100 == 0:
        print(f"Epoch [{epoch + 1}/{num_epochs}], "
              f"è®­ç»ƒæŸå¤±: {loss.item():.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_accuracy.item():.4f}, "
              f"æµ‹è¯•æŸå¤±: {test_loss.item():.4f}, æµ‹è¯•å‡†ç¡®ç‡: {test_accuracy.item():.4f}")

# 6. å¯è§†åŒ–è®­ç»ƒç»“æœ
print("5. å¯è§†åŒ–è®­ç»ƒç»“æœ...")
fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# æŸå¤±æ›²çº¿
axes[0].plot(train_losses, label='è®­ç»ƒæŸå¤±', alpha=0.7)
axes[0].plot(test_losses, label='æµ‹è¯•æŸå¤±', alpha=0.7)
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Loss')
axes[0].set_title('æŸå¤±æ›²çº¿')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# å‡†ç¡®ç‡æ›²çº¿
axes[1].plot(train_accuracies, label='è®­ç»ƒå‡†ç¡®ç‡', alpha=0.7)
axes[1].plot(test_accuracies, label='æµ‹è¯•å‡†ç¡®ç‡', alpha=0.7)
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('Accuracy')
axes[1].set_title('å‡†ç¡®ç‡æ›²çº¿')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()

# 7. å¯è§†åŒ–å†³ç­–è¾¹ç•Œ
print("6. å¯è§†åŒ–å†³ç­–è¾¹ç•Œ...")
fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# ç”Ÿæˆç½‘æ ¼ç‚¹
x_min, x_max = X_scaled[:, 0].min() - 0.5, X_scaled[:, 0].max() + 0.5
y_min, y_max = X_scaled[:, 1].min() - 0.5, X_scaled[:, 1].max() + 0.5
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),
                     np.arange(y_min, y_max, 0.02))

# é¢„æµ‹æ•´ä¸ªç½‘æ ¼
with torch.no_grad():
    grid_tensor = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)
    Z = model(grid_tensor)
    Z = (Z > 0.5).float().numpy()
    Z = Z.reshape(xx.shape)

# å†³ç­–è¾¹ç•Œ
axes[0].contourf(xx, yy, Z, alpha=0.3, cmap='viridis')
axes[0].scatter(X_train[:, 0], X_train[:, 1], c=y_train,
                edgecolors='k', cmap='viridis', alpha=0.7)
axes[0].set_xlabel('ç‰¹å¾1')
axes[0].set_ylabel('ç‰¹å¾2')
axes[0].set_title('è®­ç»ƒé›†å†³ç­–è¾¹ç•Œ')

# æµ‹è¯•é›†
axes[1].contourf(xx, yy, Z, alpha=0.3, cmap='viridis')
axes[1].scatter(X_test[:, 0], X_test[:, 1], c=y_test,
                edgecolors='k', cmap='viridis', alpha=0.7)
axes[1].set_xlabel('ç‰¹å¾1')
axes[1].set_ylabel('ç‰¹å¾2')
axes[1].set_title('æµ‹è¯•é›†å†³ç­–è¾¹ç•Œ')

plt.tight_layout()
plt.show()

# 8. æ¨¡å‹è¯„ä¼°
print("7. æœ€ç»ˆæ¨¡å‹è¯„ä¼°...")
model.eval()
with torch.no_grad():
    # è®­ç»ƒé›†è¯„ä¼°
    y_train_pred = model(X_train_tensor)
    train_predictions = (y_train_pred > 0.5).float()
    train_accuracy = (train_predictions == y_train_tensor).float().mean()

    # æµ‹è¯•é›†è¯„ä¼°
    y_test_pred = model(X_test_tensor)
    test_predictions = (y_test_pred > 0.5).float()
    test_accuracy = (test_predictions == y_test_tensor).float().mean()

print(f"æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {train_accuracy.item():.4f}")
print(f"æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_accuracy.item():.4f}")

# 9. ä¿å­˜æ¨¡å‹
print("8. ä¿å­˜æ¨¡å‹...")
torch.save(model.state_dict(), 'simple_nn_model.pth')
print("æ¨¡å‹å·²ä¿å­˜ä¸º 'simple_nn_model.pth'")

# 10. åŠ è½½æ¨¡å‹ç¤ºä¾‹
print("9. åŠ è½½æ¨¡å‹ç¤ºä¾‹...")
new_model = SimpleNN()
new_model.load_state_dict(torch.load('simple_nn_model.pth'))
new_model.eval()

# æµ‹è¯•åŠ è½½çš„æ¨¡å‹
with torch.no_grad():
    test_pred = new_model(X_test_tensor[:5])  # é¢„æµ‹å‰5ä¸ªæ ·æœ¬
    print(f"å‰5ä¸ªæµ‹è¯•æ ·æœ¬çš„é¢„æµ‹æ¦‚ç‡: {test_pred.squeeze().numpy()}")
    print(f"å‰5ä¸ªæµ‹è¯•æ ·æœ¬çš„å®é™…æ ‡ç­¾: {y_test[:5]}")

print("\n" + "=" * 50)
print("âœ… ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œå®Œæˆï¼")
print("=" * 50)